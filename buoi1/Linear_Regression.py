import streamlit as st
import pandas as pd
from scipy.stats import zscore
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from scipy.stats import zscore
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import mean_squared_error
import mlflow
import io
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler


import os
from mlflow.tracking import MlflowClient
from scipy.stats import zscore 
def mlflow_input():
    st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/PTToan250303/Linear_replication.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url']=DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "PTToan250303"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "5ca8caf353d564c358852da97c7487e64fc30a73"

    mlflow.set_experiment("Linear_replication")








def drop(df):
    st.subheader("üóëÔ∏è X√≥a c·ªôt d·ªØ li·ªáu")
    
    if "df" not in st.session_state:
        st.session_state.df = df  # L∆∞u v√†o session_state n·∫øu ch∆∞a c√≥

    df = st.session_state.df
    columns_to_drop = st.multiselect("üìå Ch·ªçn c·ªôt mu·ªën x√≥a:", df.columns.tolist())

    if st.button("üöÄ X√≥a c·ªôt ƒë√£ ch·ªçn"):
        if columns_to_drop:
            df = df.drop(columns=columns_to_drop)  # T·∫°o b·∫£n sao thay v√¨ inplace=True
            st.session_state.df = df  # C·∫≠p nh·∫≠t session_state
            st.success(f"‚úÖ ƒê√£ x√≥a c·ªôt: {', '.join(columns_to_drop)}")
            st.dataframe(df.head())
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·ªôt ƒë·ªÉ x√≥a!")

    return df

def choose_label(df):
    st.subheader("üéØ Ch·ªçn c·ªôt d·ª± ƒëo√°n (label)")

    if "target_column" not in st.session_state:
        st.session_state.target_column = None
    
    selected_label = st.selectbox("üìå Ch·ªçn c·ªôt d·ª± ƒëo√°n", df.columns, 
                                  index=df.columns.get_loc(st.session_state.target_column) if st.session_state.target_column else 0)

    X, y = df.drop(columns=[selected_label]), df[selected_label]  # M·∫∑c ƒë·ªãnh
    
    if st.button("‚úÖ X√°c nh·∫≠n Label"):
        st.session_state.target_column = selected_label
        X, y = df.drop(columns=[selected_label]), df[selected_label]
        st.success(f"‚úÖ ƒê√£ ch·ªçn c·ªôt: **{selected_label}**")
    
    return X, y

       
def xu_ly_gia_tri_thieu(df):
    if "df" not in st.session_state:
        st.session_state.df = df.copy()
    df = st.session_state.df

    # T√¨m c√°c c·ªôt c√≥ gi√° tr·ªã thi·∫øu
    missing_cols = df.columns[df.isnull().any()].tolist()

    if not missing_cols:
        st.success("‚úÖ D·ªØ li·ªáu kh√¥ng c√≥ gi√° tr·ªã thi·∫øu!")
        return df

    st.write("### üìå Khi n√†o n√™n ch·ªçn ph∆∞∆°ng ph√°p x·ª≠ l√Ω?")
    st.info("- **X√≥a gi√° tr·ªã thi·∫øu**: N·∫øu s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu √≠t ho·∫∑c qu√° nhi·ªÅu so v·ªõi t·ªïng d·ªØ li·ªáu.\n"
            "- **Thay th·∫ø b·∫±ng Mean (Trung b√¨nh)**: N·∫øu d·ªØ li·ªáu c√≥ ph√¢n ph·ªëi chu·∫©n v√† kh√¥ng c√≥ qu√° nhi·ªÅu outliers.\n"
            "- **Thay th·∫ø b·∫±ng Median (Trung v·ªã)**: N·∫øu d·ªØ li·ªáu c√≥ nhi·ªÅu ph√¢n ph·ªëi l·ªách.\n"
            "- **Thay th·∫ø b·∫±ng Mode (Gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t)**: N·∫øu d·ªØ li·ªáu thu·ªôc d·∫°ng ph√¢n lo·∫°i (category).")

    selected_cols = st.multiselect("üìå Ch·ªçn c·ªôt ch·ª©a gi√° tr·ªã thi·∫øu:", missing_cols)
    method = st.radio("üîß Ch·ªçn ph∆∞∆°ng ph√°p x·ª≠ l√Ω:", ["X√≥a gi√° tr·ªã thi·∫øu", "Thay th·∫ø b·∫±ng Mean", "Thay th·∫ø b·∫±ng Median", "Thay th·∫ø b·∫±ng Mode"])

    if st.button("üöÄ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu"):
        for col in selected_cols:
            if method == "X√≥a gi√° tr·ªã thi·∫øu":
                df = df.dropna(subset=[col])
            elif method == "Thay th·∫ø b·∫±ng Mean":
                df[col] = df[col].fillna(df[col].mean())
            elif method == "Thay th·∫ø b·∫±ng Median":
                df[col] = df[col].fillna(df[col].median())
            elif method == "Thay th·∫ø b·∫±ng Mode":
                df[col] = df[col].fillna(df[col].mode()[0])
        
        st.session_state.df = df
        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu cho c√°c c·ªôt ƒë√£ ch·ªçn")
    
    st.dataframe(df.head())
    return df

def chuyen_doi_kieu_du_lieu(df):

    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

    if not categorical_cols:
        st.success("‚úÖ Kh√¥ng c√≥ c·ªôt d·∫°ng chu·ªói c·∫ßn chuy·ªÉn ƒë·ªïi!")
        return df
    st.write("Chuy·ªÉn v·ªÅ ki·ªÉu d·ªØ li·ªáu s·ªë nguy√™n t·ª´ 1-n")
    selected_col = st.selectbox("üìå C·ªôt c·∫ßn chuy·ªÉn ƒë·ªïi:", categorical_cols)
    unique_values = df[selected_col].unique()

    if "text_inputs" not in st.session_state:
        st.session_state.text_inputs = {}

    if "mapping_dicts" not in st.session_state:
        st.session_state.mapping_dicts = []

    mapping_dict = {}
    input_values = []
    has_duplicate = False
    has_empty = False  # Ki·ªÉm tra n·∫øu c√≥ √¥ tr·ªëng

    st.write("### C√°c gi√° tr·ªã c·∫ßn chuy·ªÉn ƒë·ªïi:")
    for val in unique_values:
        st.write(f"- `{val}`")  # Hi·ªÉn th·ªã t·ª´ng gi√° tr·ªã tr√™n m·ªôt d√≤ng

    if len(unique_values) < 10:
        for val in unique_values:
            key = f"{selected_col}_{val}"
            if key not in st.session_state.text_inputs:
                st.session_state.text_inputs[key] = ""

            new_val = st.text_input(f"üîÑ Nh·∫≠p gi√° tr·ªã thay th·∫ø cho `{val}`:", 
                                    key=key, 
                                    value=st.session_state.text_inputs[key])

            st.session_state.text_inputs[key] = new_val
            input_values.append(new_val)
            mapping_dict[val] = new_val

        # Ki·ªÉm tra √¥ tr·ªëng
        if "" in input_values:
            has_empty = True

        # Ki·ªÉm tra tr√πng l·∫∑p
        duplicate_values = [val for val in input_values if input_values.count(val) > 1 and val != ""]
        if duplicate_values:
            has_duplicate = True
            st.warning(f"‚ö† Gi√° tr·ªã `{', '.join(set(duplicate_values))}` ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng nhi·ªÅu l·∫ßn. Vui l√≤ng ch·ªçn s·ªë kh√°c!")

        # N√∫t b·ªã m·ªù n·∫øu c√≥ tr√πng ho·∫∑c ch∆∞a nh·∫≠p ƒë·ªß gi√° tr·ªã
        btn_disabled = has_duplicate or has_empty

        if st.button("üöÄ Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu", disabled=btn_disabled):
            column_info = {"column_name": selected_col, "mapping_dict": mapping_dict}
            st.session_state.mapping_dicts.append(column_info)

            df[selected_col] = df[selected_col].map(lambda x: mapping_dict.get(x, x))
            df[selected_col] = pd.to_numeric(df[selected_col], errors='coerce')

            st.session_state.text_inputs.clear()
            st.session_state.df = df
            st.success(f"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt `{selected_col}`")

    st.dataframe(df.head())
    return df









def chuan_hoa_du_lieu(df):
    # st.subheader("üìä Chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi SMinMaxScaler")

    # L·ªçc t·∫•t c·∫£ c√°c c·ªôt s·ªë
    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

    # T√¨m c√°c c·ªôt nh·ªã ph√¢n (ch·ªâ ch·ª©a 0 v√† 1)
    binary_cols = [col for col in numerical_cols if df[col].dropna().isin([0, 1]).all()]

    # Lo·∫°i b·ªè c·ªôt nh·ªã ph√¢n kh·ªèi danh s√°ch c·∫ßn chu·∫©n h√≥a
    cols_to_scale = list(set(numerical_cols) - set(binary_cols))

    if not cols_to_scale:
        st.success("‚úÖ Kh√¥ng c√≥ thu·ªôc t√≠nh d·∫°ng s·ªë c·∫ßn chu·∫©n h√≥a!")
        return df

    if st.button("üöÄ Th·ª±c hi·ªán Chu·∫©n h√≥a"):
        scaler = MinMaxScaler()
        df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])

        # L∆∞u v√†o session_state
        st.session_state.df = df

        st.success(f"‚úÖ ƒê√£ chu·∫©n h√≥a xong")
        st.dataframe(df.head())

    return df

def hien_thi_ly_thuyet(df):

                # Ki·ªÉm tra l·ªói d·ªØ li·ªáu
    st.subheader("üö® Ki·ªÉm tra d·ªØ li·ªáu")
                # Ki·ªÉm tra gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()

                # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()

                # T·∫°o b√°o c√°o l·ªói
    error_report = pd.DataFrame({
        'Gi√° tr·ªã thi·∫øu': missing_values,
        'D·ªØ li·ªáu tr√πng l·∫∑p': duplicate_count,
        'T·ªâ l·ªá tr√πng l·∫∑p (%)': round((duplicate_count / df.shape[0]) * 100,2),
        'Ki·ªÉu d·ªØ li·ªáu': df.dtypes.astype(str)
    })

                # Hi·ªÉn th·ªã b√°o c√°o l·ªói
    st.table(error_report)          
   
    
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

    # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc
    
    st.header("‚öôÔ∏è C√°c b∆∞·ªõc ch√≠nh trong ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    st.subheader("1Ô∏è‚É£ Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt")


    df=drop(df)
    
    st.subheader("2Ô∏è‚É£ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")
    df=xu_ly_gia_tri_thieu(df)

    st.subheader("3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")

    df=chuyen_doi_kieu_du_lieu(df)
    
    st.subheader("4Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë")
 
    df=chuan_hoa_du_lieu(df)
def train_test_size():
    if "df" not in st.session_state:
        st.error("‚ùå D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c t·∫£i l√™n!")
        st.stop()
    
    df = st.session_state.df  # L·∫•y d·ªØ li·ªáu t·ª´ session_stat
    X, y = choose_label(df)
    
    st.subheader("üìä Chia d·ªØ li·ªáu Train - Validation - Test")   
    
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)

    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    

    if st.button("‚úÖ X√°c nh·∫≠n Chia"):
        # st.write("‚è≥ ƒêang chia d·ªØ li·ªáu...")

        stratify_option = y if y.nunique() > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X, y, test_size=test_size/100, stratify=stratify_option, random_state=42
        )

        stratify_option = y_train_full if y_train_full.nunique() > 1 else None
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_size / (100 - test_size),
            stratify=stratify_option, random_state=42
        )

        # st.write(f"üìä K√≠ch th∆∞·ªõc t·∫≠p Train: {X_train.shape[0]} m·∫´u")
        # st.write(f"üìä K√≠ch th∆∞·ªõc t·∫≠p Validation: {X_val.shape[0]} m·∫´u")
        # st.write(f"üìä K√≠ch th∆∞·ªõc t·∫≠p Test: {X_test.shape[0]} m·∫´u")

        # L∆∞u v√†o session_state
        st.session_state.X_train = X_train
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_test = y_test
        st.session_state.y = y
        st.session_state.X_train_shape = X_train.shape[0]
        st.session_state.X_val_shape = X_val.shape[0]
        st.session_state.X_test_shape = X_test.shape[0]
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.table(summary_df)

        # **Log d·ªØ li·ªáu v√†o MLflow**    
def chia():
    st.subheader("Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test")
    st.write("""
    ### üìå Chia t·∫≠p d·ªØ li·ªáu
    D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh ba ph·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh t·ªïng qu√°t t·ªët:
    - **Trian(%)**: ƒë·ªÉ train m√¥ h√¨nh.
    - **Val (%)**: ƒë·ªÉ validation, d√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë.
    - **Test(%)**: ƒë·ªÉ test, ƒë√°nh gi√° hi·ªáu su·∫•t th·ª±c t·∫ø.
    """)
    train_test_size()

from sklearn.pipeline import make_pipeline   
from sklearn.model_selection import train_test_split, cross_val_score

def train_multiple_linear_regression(X_train, y_train, learning_rate=0.001, n_iterations=200):
    """Hu·∫•n luy·ªán h·ªìi quy tuy·∫øn t√≠nh b·ªôi b·∫±ng Gradient Descent."""
    
    # Chuy·ªÉn ƒë·ªïi X_train, y_train sang NumPy array ƒë·ªÉ tr√°nh l·ªói
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # Ki·ªÉm tra NaN ho·∫∑c Inf
    if np.isnan(X_train).any() or np.isnan(y_train).any():
        raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã NaN!")
    if np.isinf(X_train).any() or np.isinf(y_train).any():
        raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã v√¥ c√πng (Inf)!")

    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = MinMaxScaler()
    X_train = scaler.fit_transform(X_train)

    # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
    m, n = X_train.shape
    #st.write(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

    # Th√™m c·ªôt bias (x0 = 1) v√†o X_train
    X_b = np.c_[np.ones((m, 1)), X_train]
    #st.write(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

    # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
    w = np.random.randn(X_b.shape[1], 1) * 0.01  
    #st.write(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

    # Gradient Descent
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

        # Ki·ªÉm tra xem gradients c√≥ NaN kh√¥ng
        # st.write(gradients)
        if np.isnan(gradients).any():
            raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

        w -= learning_rate * gradients

    #st.success("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
    #st.write(f"Tr·ªçng s·ªë cu·ªëi c√πng: {w.flatten()}")
    return w
def train_polynomial_regression(X_train, y_train, degree=2, learning_rate=0.001, n_iterations=500):
    """Hu·∫•n luy·ªán h·ªìi quy ƒëa th·ª©c **kh√¥ng c√≥ t∆∞∆°ng t√°c** b·∫±ng Gradient Descent."""

    # Chuy·ªÉn d·ªØ li·ªáu sang NumPy array n·∫øu l√† pandas DataFrame/Series
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # T·∫°o ƒë·∫∑c tr∆∞ng ƒëa th·ª©c **ch·ªâ th√™m b·∫≠c cao, kh√¥ng c√≥ t∆∞∆°ng t√°c**
    X_poly = np.hstack([X_train] + [X_train**d for d in range(2, degree + 1)])
    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = MinMaxScaler()
    X_poly = scaler.fit_transform(X_poly)

    # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
    m, n = X_poly.shape
    print(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

    # Th√™m c·ªôt bias (x0 = 1)
    X_b = np.c_[np.ones((m, 1)), X_poly]
    print(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

    # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
    w = np.random.randn(X_b.shape[1], 1) * 0.01  
    print(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

    # Gradient Descent
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

        # Ki·ªÉm tra n·∫øu gradient c√≥ gi√° tr·ªã NaN
        if np.isnan(gradients).any():
            raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

        w -= learning_rate * gradients

    print("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
    print(f"Tr·ªçng s·ªë cu·ªëi c√πng: {w.flatten()}")
    
    return w




def chon_mo_hinh():
    st.subheader("üîç Ch·ªçn m√¥ h√¨nh h·ªìi quy")

    model_type_V = st.radio("Ch·ªçn lo·∫°i m√¥ h√¨nh:", ["Multiple Linear Regression", "Polynomial Regression"])
    model_type = "linear" if model_type_V == "Multiple Linear Regression" else "polynomial"

    n_folds = st.slider("Ch·ªçn s·ªë folds (KFold Cross-Validation):", min_value=2, max_value=10, value=5)
    learning_rate = st.slider("Ch·ªçn t·ªëc ƒë·ªô h·ªçc (learning rate):", 
                              min_value=1e-6, max_value=0.1, value=0.01, step=1e-6, format="%.6f")

    degree = 2
    if model_type == "polynomial":
        degree = st.slider("Ch·ªçn b·∫≠c ƒëa th·ª©c:", min_value=2, max_value=5, value=2)

    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)

    if "X_train" not in st.session_state or st.session_state.X_train is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán m√¥ h√¨nh!")
        return None, None

    X_train, X_test = st.session_state.X_train, st.session_state.X_test
    y_train, y_test = st.session_state.y_train, st.session_state.y_test
    df = st.session_state.df  # L·∫•y to√†n b·ªô dataset

    # üîπ **Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho 'run_name' n·∫øu ch∆∞a c√≥**
    if "run_name" not in st.session_state:
        st.session_state["run_name"] = "default_run"

    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", st.session_state["run_name"])
    st.session_state["run_name"] = run_name if run_name else "default_run"

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            # üåü **L∆∞u th√¥ng tin d·ªØ li·ªáu v√†o MLflow**
            mlflow.log_param("dataset_shape", df.shape)
            mlflow.log_param("target_column", st.session_state.y.name)
            mlflow.log_param("train_size", st.session_state.X_train_shape)
            mlflow.log_param("validation_size", st.session_state.X_val_shape)
            mlflow.log_param("test_size", st.session_state.X_test_shape)

            # üåü **L∆∞u dataset l√™n MLflow**
            dataset_path = "dataset.csv"
            df.to_csv(dataset_path, index=False)
            mlflow.log_artifact(dataset_path)

            # üåü **L∆∞u tham s·ªë m√¥ h√¨nh v√†o MLflow**
            mlflow.log_param("model_type", model_type)
            mlflow.log_param("n_folds", n_folds)
            mlflow.log_param("learning_rate", learning_rate)
            if model_type == "polynomial":
                mlflow.log_param("degree", degree)

            fold_mse = []
            best_model = None

            for train_idx, valid_idx in kf.split(X_train, y_train):
                X_train_fold, X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]
                y_train_fold, y_valid = y_train.iloc[train_idx], y_train.iloc[valid_idx]

                if model_type == "linear":
                    model = LinearRegression()
                    model.fit(X_train_fold, y_train_fold)
                    y_valid_pred = model.predict(X_valid)
                else:  
                    poly_features = PolynomialFeatures(degree=degree)
                    X_train_poly = poly_features.fit_transform(X_train_fold)
                    X_valid_poly = poly_features.transform(X_valid)

                    model = LinearRegression()
                    model.fit(X_train_poly, y_train_fold)
                    y_valid_pred = model.predict(X_valid_poly)

                mse = mean_squared_error(y_valid, y_valid_pred)
                fold_mse.append(mse)

            avg_mse = np.mean(fold_mse)
            mlflow.log_metric("avg_mse", avg_mse)  # üåü L∆∞u MSE trung b√¨nh v√†o MLflow

            # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n to√†n b·ªô t·∫≠p train
            if model_type == "linear":
                final_model = LinearRegression()
                final_model.fit(X_train, y_train)
                st.session_state['linear_model'] = final_model
            else:
                poly_features = PolynomialFeatures(degree=degree)
                X_train_poly = poly_features.fit_transform(X_train)

                final_model = LinearRegression()
                final_model.fit(X_train_poly, y_train)

                # L∆∞u m√¥ h√¨nh v√† PolynomialFeatures v√†o session_state
                st.session_state['polynomial_model'] = final_model
                st.session_state['poly_features'] = poly_features

            # üåü **T√≠nh to√°n MSE tr√™n t·∫≠p Train & Test**
            if model_type == "linear":
                y_train_pred = final_model.predict(X_train)
                y_test_pred = final_model.predict(X_test)
            else:
                X_test_poly = poly_features.transform(X_test)
                y_train_pred = final_model.predict(X_train_poly)
                y_test_pred = final_model.predict(X_test_poly)

            train_mse = mean_squared_error(y_train, y_train_pred)
            test_mse = mean_squared_error(y_test, y_test_pred)

            mlflow.log_metric("train_mse", train_mse)  # üåü L∆∞u MSE train
            mlflow.log_metric("test_mse", test_mse)    # üåü L∆∞u MSE test

            st.success(f"MSE trung b√¨nh qua c√°c folds: {avg_mse:.4f}")
            st.success(f"MSE tr√™n t·∫≠p train: {train_mse:.4f}")
            st.success(f"MSE tr√™n t·∫≠p test: {test_mse:.4f}")

        return final_model, avg_mse, test_mse

    return None, None, None



import numpy as np
import streamlit as st

def test():
    # Ki·ªÉm tra xem m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u trong session_state ch∆∞a
    model_type = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["linear", "polynomial"])
    
    if model_type == "linear" and "linear_model" in st.session_state:
        model = st.session_state["linear_model"]
    elif model_type == "polynomial" and "polynomial_model" in st.session_state:
        model = st.session_state["polynomial_model"]
        poly_features = st.session_state.get("poly_features", None)
        if poly_features is None:
            st.error("Kh√¥ng t√¨m th·∫•y poly_features trong session_state")
            return
    else:
        st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán.")
        return
    
    # L·∫•y d·ªØ li·ªáu hu·∫•n luy·ªán
    X_train = st.session_state.X_train
    column_names = X_train.columns.tolist()
    
    # Nh·∫≠p gi√° tr·ªã t·ª´ ng∆∞·ªùi d√πng
    X_train_input = []
    for i, column_name in enumerate(column_names):
        value = st.number_input(f"Gi√° tr·ªã c·ªôt {column_name}", key=f"column_{i}")
        X_train_input.append(value)
    
    X_train_input = np.array(X_train_input).reshape(1, -1)
    
    # X·ª≠ l√Ω v·ªõi polynomial model
    if model_type == "polynomial":
        X_train_input = poly_features.transform(X_train_input)
    
    # D·ª± ƒëo√°n k·∫øt qu·∫£
    if st.button("D·ª± ƒëo√°n"):
        y_pred = model.predict(X_train_input)
        
        prediction_label = "S·ªëng üü¢" if y_pred[0] >= 0.5 else "Ch·∫øt üî¥"
        st.write(f"D·ª± ƒëo√°n: {prediction_label}")
        
        y_train = st.session_state.y_train
        y_mean = np.mean(y_train)
        
        # Ki·ªÉm tra tr√°nh l·ªói chia cho 0
        if y_mean != 0:
            reliability = max(0, 1 - abs(y_pred[0] - y_mean) / y_mean) * 100
            st.write(f"üîç ƒê·ªô tin c·∫≠y: {reliability:.2f}%")
        else:
            st.write("üîç Kh√¥ng th·ªÉ t√≠nh ƒë·ªô tin c·∫≠y v√¨ y_mean = 0")

            
            
import streamlit as st
import mlflow
import os

import streamlit as st
import mlflow
import os
import pandas as pd
from datetime import datetime
def show_experiment_selector():
    st.title("üìä MLflow Experiments - DAGsHub")

    # K·∫øt n·ªëi v·ªõi DAGsHub MLflow Tracking
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ experiments
    experiment_name = "Linear_replication"
    
    # T√¨m experiment theo t√™n
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # L·∫•y danh s√°ch run_name t·ª´ params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")  # N·∫øu kh√¥ng c√≥ run_name th√¨ l·∫•y run_id
        run_info.append((run_name, run_id))

    # T·∫°o dictionary ƒë·ªÉ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())

    # Ch·ªçn run theo run_name
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa run ƒë∆∞·ª£c ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds

# Chuy·ªÉn sang ƒë·ªãnh d·∫°ng ng√†y gi·ªù d·ªÖ ƒë·ªçc
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Ki·ªÉm tra v√† hi·ªÉn th·ªã dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv"
        st.write("### üìÇ Dataset:")
        st.write(f"üì• [T·∫£i dataset]({dataset_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")




          
def chon():
    try:
                
        final_w, avg_mse, test_mse = chon_mo_hinh()
    except Exception as e:
        st.error(f"L·ªói x·∫£y ra: {e}")


def data(df):
    """Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ t·∫£i l√™n"""
    if df is not None:
        st.success("üìÇ File ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n th√†nh c√¥ng!")
        hien_thi_ly_thuyet(df)
    else:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã.")
            
import streamlit as st
import mlflow
import os

import streamlit as st
import mlflow
import os
import pandas as pd
from datetime import datetime
def show_experiment_selector():
    st.title("üìä MLflow Experiments - DAGsHub")

    # K·∫øt n·ªëi v·ªõi DAGsHub MLflow Tracking
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ experiments
    experiment_name = "Linear_replication"
    
    # T√¨m experiment theo t√™n
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # L·∫•y danh s√°ch run_name t·ª´ params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")  # N·∫øu kh√¥ng c√≥ run_name th√¨ l·∫•y run_id
        run_info.append((run_name, run_id))

    # T·∫°o dictionary ƒë·ªÉ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())

    # Ch·ªçn run theo run_name
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa run ƒë∆∞·ª£c ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds

# Chuy·ªÉn sang ƒë·ªãnh d·∫°ng ng√†y gi·ªù d·ªÖ ƒë·ªçc
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Ki·ªÉm tra v√† hi·ªÉn th·ªã dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv"
        st.write("### üìÇ Dataset:")
        st.write(f"üì• [T·∫£i dataset]({dataset_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")
def chon():
    try:
        final_w, avg_mse, scaler = chon_mo_hinh()
    except Exception as e:
        st.error(f"‚ùå L·ªói khi ch·ªçn m√¥ h√¨nh: {e}")
def Classification():
    # ƒê·ªãnh d·∫°ng ti√™u ƒë·ªÅ
    st.markdown("""
        <style>
        .title {
            font-size: 48px;
            font-weight: bold;
            text-align: center;
            color: #4682B4;
            margin-top: 50px;
        }
        .subtitle {
            font-size: 24px;
            text-align: center;
            color: #4A4A4A;
        }
        hr {
            border: 1px solid #ddd;
        }
        </style>
        <div class="title">Linear Regression</div>
        <hr>
    """, unsafe_allow_html=True)

    # Cho ph√©p ng∆∞·ªùi d√πng t·∫£i m·ªôt file duy nh·∫•t
    uploaded_file = st.file_uploader("üì• Ch·ªçn m·ªôt file dataset", type=["csv", "xlsx"])

    if uploaded_file:
        try:
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
                st.write("ƒê·ªãnh d·∫°ng t·ªáp CSV h·ª£p l·ªá.")
            else:
                st.error("‚ùå ƒê·ªãnh d·∫°ng t·ªáp kh√¥ng h·ª£p l·ªá. Vui l√≤ng t·∫£i l·∫°i t·ªáp .csv")
                return  # D·ª´ng ch∆∞∆°ng tr√¨nh n·∫øu t·∫£i sai file
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc t·ªáp: {e}")
            return

        st.success(f"‚úÖ ƒê√£ t·∫£i l√™n: {uploaded_file.name}")
        st.write(df)  # Hi·ªÉn th·ªã to√†n b·ªô dataset

        # Ch·ªâ hi·ªÉn th·ªã thanh ƒëi·ªÅu h∆∞·ªõng khi c√≥ file h·ª£p l·ªá
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üìò L√Ω thuy·∫øt", 
            "üìä X·ª≠ l√Ω d·ªØ li·ªáu",
            "‚öôÔ∏è Hu·∫•n luy·ªán", 
            "üí° Demo",
            "üìù MLflow"
        ])

        with tab1:
            st.write("L√Ω thuy·∫øt ")
        with tab2:
            data(df)
        with tab3:
            chia()
            chon()
        with tab4:
            test()
        with tab5:
            show_experiment_selector()

if __name__ == "__main__":
    Classification()
